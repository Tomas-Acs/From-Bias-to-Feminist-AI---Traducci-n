# Capítulo 1: Nosotros formamos nuestras herramientas de la misma manera que nuestras herramientas nos forman

Esta máxima representa un peligro particular para las mujeres y niñas del sur global, históricamente marginalizadas y sistemáticamente excluidas de tecnología, toma de decisiones o de múltiples oportunidades para participar en crear sus propias soluciones.

Por: [Caitlin Kraft-Buchman](https://feministai.pubpub.org/user/caitlin-kraft-buchman)  

-----------------


 Como Marshall McLuhan dijo famosamente, “Nosotros formamos nuestras herramientas de la misma manera que nuestras herramientas nos forman”.  
 
Esta máxima representa un peligro particular para las mujeres y niñas del sur global, históricamente marginalizadas y sistemáticamente excluidas de tecnología, toma de decisiones o de múltiples oportunidades para participar en crear sus propias soluciones para los grandes problemas sociales que buscamos que la tecnología arregle. Esto es algo particularmente urgente dado la escala en la que la Inteligencia Artificial (AI) y los algoritmos de decisión (ADM) están siendo distribuidos globalmente como la normativa, están tan unidos al sistema que se vuelven maquinas inconscientes e intratables, las cuales ejecutan viejas normas y estereotipos que aprenden de otros patrones aprendidos de maquinas viejas.  


El aprendizaje automático (Machine learning) hace que la información que esta implícita en la información se materialice (incluida la “información faltante” de mujeres, niñas y otros grupos históricamente marginalizados haciéndolos invisibles en la información). Esta invisibilidad se vuelve explicita en el código ya que el aprendizaje automático “imita inteligentemente” la información que se la suministrado del mundo analógico.  De esta manera si las reglas de “genero” las cuales se van quitando paulatinamente del mundo, se programan dentro del AI y los algoritmos de decisión, estás van a volver de una manera mucho más fuerte y efectiva, creando un patriarcado 2.0 aún más difícil de erradicar que las actuales estructuras coloniales y patriarcales.  


Sin embargo, tenemos una pequeña oportunidad para crear nuevas normas ahora.  

Hay que actuar rápidamente. Compuesto por la pandemia del COVID-19, desarrollo acelerado publico y privado de despliegue de AI en el norte global, esto se va a ver reflejado en el norte como en el sur, aumentando el peligro de que el sur global va a ser abandonado y dejado atrás en investigación, aplicación y despliegue de AI; todavía menos AI enfocado en problemas del sur global o problemas del sur global feministas. La falta de presupuesto de investigación, capacidad, migración de talento y conflicto de prioridades pueden dejar al sur global sin opción más que adoptar tecnología que no está moldeada a sus realidad y necesidades. Esto va a ser una perdida para un mundo que necesita más invención y más diversidad en su innovación. En esta situación, se va a ampliar aún más la información obsoleta dentro de los modelos de datos, ampliando la exclusión para aquellos grupos históricamente marginalizados de mujeres y niñas. [^1]  


Es importante hacer notar que las mujeres y niñas pueden y son una forma de darle voz a todos aquellos grupos tradicionalmente invisibles, aquellos tradicionalmente dejados atrás. La información de datos feminista es inseparable de la “interseccionalidad”, “la naturaleza interconectada de categorías sociales como la clase, raza y genero mientras se aplican a cierto individuo o grupo, considerado como una superposición y sistemas interdependientes de discriminación y desventaja”. Nuestra discusión es igualmente poderosa (con ese propósito) y aplicable a otras formas de discriminación, más notablemente discriminación racial. [^2]  

Estamos en un punto de inflección.  

# El Paisaje
