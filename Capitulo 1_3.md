# Practicando principios feministas en el diseño de Inteligencia Artificial

La inteligencia artificial puede servir para desafiar la desigualdad social y desmantelar estructuras de poder.

Por [Ambika Tandon](https://feministai.pubpub.org/user/ambika-tandon)

---


“*Los principios feministas pueden ser un marco de referencia útil para entender y transformar el impacto de los sistemas de inteligencia artificial. Algunos principios claves incluye reflexividad, participación, interseccionalidad y trabajar hacia un cambio estructural.*” 

Los sistemas de inteligencia artificial han sido heraldos de herramientas para purgar nuestros sistemas de sesgos sociales, opiniones, comportamientos y producir “objetividad”. Sin embargo, en lo contrario, se ha vuelto evidente que los sistemas de AI pueden fortalecer la desigualdad y sesgos al programarlos. Si no se atiende, las decisiones automatizadas pueden ser peligrosas y distópicas.  

**Sin embargo, si es apropiado por feministas, la AI puede servir para desafiar la desigualdad y desmantelar estructuras de poder. Hay muchas rutas para lograr esta apropiación, resistir métodos autoritarios a través de la construcción de movimientos y creando nuestros sistemas alternativos que reutilizan el poder del AI para lograr un cambio social.**  

**Los principios feministas pueden ser un marco de referencia útil para entender y transformar el impacto de los sistemas de inteligencia artificial. Algunos principios claves incluye reflexividad, participación, interseccionalidad y trabajar hacia un cambio estructural. ** Cuando son puestos en acción, estos principios pueden usarse para mejorar las capacidades de actores locales y de instituciones que trabajan por el desarrollo. También se pueden utilizar para teoréticamente hacer grupo contra el uso de AI en sistemas de poder.  

**Reflexividad** en el diseño y en la implementación de AI significaría un vistazo en el privilegio y en el poder, o la falta de, en los múltiples interesados en un ecosistema. Al ser reflexivos, los diseñadores pueden tomar pasos para contrarrestar las jerarquías de poder en los procesos de diseño. Un ejemplo popular de las diferencias de poder está en las estadísticas nacionales. Coleccionado principalmente por encuestadores hombres hablándole a otros hombres, lideres de casa, las estadísticas nacionales pueden muchas veces menosprecias o des representar el trabajo y la salud de las mujeres. Los sistemas de AI tendrían que ser consientes de estas diferencias para poder mitigarlas.  

**Participación** como principio se enfoca en el proceso. Un proceso participativo significaría un vistazo a las diferentes perspectivas y experiencias vividas de los diferentes interesados, incluyendo aquellos más afectados por su despliegue. **En el ecosistema de la salud, por ejemplo, esto incluiría a políticos, sector publico y privado, trabajadores de primera línea y pacientes. Un sistema de información de salud con un buen diseño determinaría su éxito por métricas no solo dictadas por organizaciones de alto nivel si no también por organizaciones como la World Health Organisation y gobiernos nacionales, suplidores y trabajadores de primera línea. ** Entre otros beneficios, participación en el diseño de sistemas de AI también permite que otros compren la tecnología y esta se vuelva estándar.  

**Interseccionalidad** para enfrentar las diferencias sociales en las bases de datos, diseño y en el despliegue de AI. **Investigaciones a través de distintas áreas han mostrado la perpetuación de la desigualdad en género, raza, nivel socioeconómico y otros factores a través del uso de AI y sus bases de datos. **  

“*El principio más crítico es asegurarse que los sistemas de AI están trabajando para desafiar la desigualdad, incluyendo la desigualdad perpetuada por sistemas patriarcales, racistas y capitalistas.*”  

 El principio más crítico es asegurarse que los sistemas de AI están trabajando para desafiar la desigualdad, incluyendo la desigualdad perpetuada por sistemas patriarcales, racistas y capitalistas. Al alinearse con los principios feministas significa que los sistemas que **no** están alineados con estos sistemas como aquellos que mejoran la capacidad del estado para espiar y utilizar fuerzas policiales serían inmediatamente excluidos. Sistemas que están diseñados para excluir y oprimir no podrían trabajar para alcanzar las metas feministas, incluso si se integrara otros principios progresistas como la información interseccional o arquitectura dinámica consensuada (la cual permitiría a los usuarios participar y salirse fácilmente).   
 
 *Sistemas que están diseñados para excluir y oprimir no podrían trabajar para alcanzar las metas feministas, incluso si se integrara otros principios progresistas como la información interseccional o arquitectura dinámica consensuada.*  

Debemos trabajar en disminuir la desigualdad social y alcanzar resultados de igualdad a través de la práctica. A pesar de que hay explícitamente proyectos feministas que producen mejores bases de datos o piden mecanismos más participatorios, los cuales claramente utilizan este principio, yo argumentaría que también es practicado por cualquier proyecto que busca aumentar los principios feministas. Por ejemplo, proyectos de AI que buscan reducir el discurso de odio y la desinformación en línea.  Dado que las mujeres y otros grupos marginalizados son muy frecuentemente los afectados de la violencia, este trabajo puede clasificarse como feminista incluso si no busca como objetivo arreglar la violencia de genero.  

Toda la tecnología esta relacionada con las relaciones sociales. Al practicar los principios feministas en los diseños de AI, esto funciona para diseñar mejores y sistemas mas robustos. **Practicantes feministas pueden movilizar estos principios para asegurarse un futuro con AI inclusivo, que todos seamos dueños, participativo y combinado con cambios colectivos a los sistemas de dominación.**




## Referencias

Haraway, Donna. “Situated Knowledges: The Science Question in Feminism and the Privilege of Partial Perspective.” Feminist Studies 14, no. 3 (1988): 575–99. https://doi.org/10.2307/3178066.
